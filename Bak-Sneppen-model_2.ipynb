{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1240f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy.optimize import curve_fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ab3fd9",
   "metadata": {},
   "source": [
    "## Creating Bak-Sneppen model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f551438",
   "metadata": {},
   "source": [
    "Steps:\n",
    "Inititalize percolation grid\n",
    "Start time loop\n",
    "For every time iteration:\n",
    "    Calculate probabilities that neighbours change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationGrid:\n",
    "    def __init__(self, size, lambda_rate = 0.9, low=0.0, high=1.0):\n",
    "        self.size = size\n",
    "        self.threshold = []\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "        self.fitness_max = -1\n",
    "        self.minima = []\n",
    "        self.history = []\n",
    "        self.num_iterations = 0\n",
    "        self.avalanche_length = []\n",
    "        self.current = self.initialize_grid()\n",
    "        self.lambda_rate = lambda_rate  # Adjust as needed\n",
    "        # Schedule the first information event\n",
    "        self.time_for_next_info = np.random.exponential(scale=1/self.lambda_rate)\n",
    "        \n",
    "    def restart(self):\n",
    "        self.current = self.initialize_grid()\n",
    "        self.history = []\n",
    "        self.threshold_fitness = []\n",
    "        self.fitness_max = -1\n",
    "\n",
    "    def initialize_grid(self):\n",
    "        return np.array([[np.random.uniform(self.low, self.high) for _ in range(self.size)] for _ in range(self.size)])\n",
    "\n",
    "    def visualize(self):\n",
    "        cmap = 'viridis'\n",
    "        plt.imshow(self.current, cmap=cmap, interpolation='nearest')\n",
    "        plt.title('2D Grid Initialized with Uniform Distribution')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    def draw_value(self):\n",
    "#         return np.random.normal(loc=self.mean, scale=self.std, size=(self.size, self.size))\n",
    "        return np.random.uniform(self.low, self.high)\n",
    "\n",
    "    def avalanche_frequencies(self):  \n",
    "        freq = {}\n",
    "        for value in self.avalanche_length:\n",
    "            if value in freq:\n",
    "                freq[value] += 1\n",
    "            else:\n",
    "                freq[value] = 1\n",
    "                \n",
    "        lst = np.array([[key,freq[key]] for key in freq])\n",
    "        sorted_indices = np.argsort(lst[:, 0])\n",
    "        # Use the sorted indices to sort the array\n",
    "        sorted_frequencies = lst[sorted_indices]\n",
    "        \n",
    "        return sorted_frequencies\n",
    "    \n",
    "    def introduce_new_information(self, current_time, num_clusters, fitness_value, lambda_rate):\n",
    "        \"\"\"\n",
    "        Introduces a cluster of new information based on an exponential distribution to \n",
    "        determine the timing of events.\n",
    "        \n",
    "        :param current_time: The current time step in the simulation.\n",
    "        :param fitness_value: The fitness value to assign to the new information clusters.\n",
    "        \"\"\"\n",
    "        if current_time >= self.time_for_next_info:\n",
    "            # Determine the number of clusters to introduce (can be based on Poisson or another approach)\n",
    "            for _ in range(num_clusters):\n",
    "                # Select a random site for the new information\n",
    "                site = np.random.randint(0, self.size)\n",
    "                # Update self.current instead of self.grid\n",
    "                i, j = np.unravel_index(site, self.current.shape)\n",
    "                self.current[i, j] = fitness_value\n",
    "\n",
    "            # Schedule the next information event\n",
    "            self.time_for_next_info += np.random.exponential(scale=1/self.lambda_rate)\n",
    "            \n",
    "    def adjust_neighbor_fitness(self, i, j):\n",
    "        \"\"\"\n",
    "        Adjusts the fitness of a neighbor based on its original value.\n",
    "        The adjustment weight is randomly chosen from U(0,1) and the direction (+ or -)\n",
    "        is determined by a Bernoulli trial.\n",
    "        \"\"\"\n",
    "        original_value = self.current[i, j]\n",
    "        weight = np.random.uniform(0, 1)  # Weight is randomly chosen from U(0,1)\n",
    "        \n",
    "#         change_direction = 1 if np.random.rand() < 0.5 else -1 # Direction is determined by a Bernoulli trial\n",
    "        change_direction = -1\n",
    "        adjustment = original_value * weight * change_direction\n",
    "        new_value = original_value + adjustment\n",
    "\n",
    "        # Ensure the new value is within the bounds -> [0,1]\n",
    "        return max(min(new_value, self.high), self.low)\n",
    "\n",
    "    def run_iterations(self, iterations, num_clusters = 0, lambda_rate = 0.9,event_fitness=0.1, save=False):\n",
    "        self.num_iterations= iterations\n",
    "        avalanche_size = 0\n",
    "        fitness_max = 0\n",
    "        for t in range(iterations):\n",
    "            \n",
    "            # Introduce new information if the time has come\n",
    "            if num_clusters > 0:\n",
    "                self.introduce_new_information(t, num_clusters, event_fitness, lambda_rate)\n",
    "            \n",
    "            #Choosing to save values \n",
    "            if save:\n",
    "                self.history.append(self.current.copy())  # Use copy to save the state, not a reference\n",
    "\n",
    "            # Getting min index and saving minimum value\n",
    "            min_index = np.unravel_index(self.current.argmin(), self.current.shape)\n",
    "            minimum = self.current[min_index[0], min_index[1]]\n",
    "            self.minima.append(minimum)\n",
    "            \n",
    "            \n",
    "            #Updating fitness threshold and saving\n",
    "            avalanche_size += 1\n",
    "            if fitness_max < minimum:\n",
    "                    self.avalanche_length.append(avalanche_size)\n",
    "                    self.threshold.append((t,minimum))\n",
    "                    fitness_max = minimum\n",
    "                    avalanche_size = 0 \n",
    "            \n",
    "\n",
    "            # I could make this part more efficient but too lazy for now\n",
    "            neighbors = [\n",
    "                (min_index[0] - 1, min_index[1]),  # Above\n",
    "                (min_index[0] + 1, min_index[1]),  # Below\n",
    "                (min_index[0], min_index[1] - 1),  # Left\n",
    "                (min_index[0], min_index[1] + 1)   # Right\n",
    "            ]\n",
    "\n",
    "            # Keeping only 'useful' indexes\n",
    "            indices = [(i, j) for i, j in neighbors if 0 <= i < self.current.shape[0] and 0 <= j < self.current.shape[1]]\n",
    "\n",
    "#             Updating neighbors and worst value\n",
    "#             for index in indices:\n",
    "#                 i, j = index\n",
    "#                 self.current[i, j] = self.draw_value()\n",
    "\n",
    "#             self.current[min_index[0], min_index[1]] = self.draw_value()\n",
    "            \n",
    "            for i, j in indices:\n",
    "#                 self.current[i, j] = self.draw_value()\n",
    "                self.current[i, j] = self.adjust_neighbor_fitness(i, j)\n",
    "                \n",
    "            self.current[min_index[0], min_index[1]] = self.draw_value()\n",
    "            \n",
    "        self.threshold = np.array(self.threshold)\n",
    "\n",
    "# An avalanche is a cascade of fitness changes below the threshold (i.e. all the blinking dots below the\n",
    "# line), although this behavior also results in random fitness changes above the line. An avalanche lasts\n",
    "# as long as any activity remains below the threshold, and the length of the avalanche is the number of\n",
    "# mutations below the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b32346",
   "metadata": {},
   "source": [
    "## Running and visualizing grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ba11b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid = SimulationGrid(100)\n",
    "grid.visualize()\n",
    "plt.show()\n",
    "#  run_iterations(self, iterations, num_clusters = 0, lambda_rate = 0.9,event_fitness=0.1, save=False)\n",
    "\n",
    "grid.run_iterations(1000000, num_clusters= 0, save=False)\n",
    "grid.visualize()\n",
    "plt.show()\n",
    "\n",
    "# plt.hist(grid.current.flatten())\n",
    "\n",
    "plt.hist(grid.minima, bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e4fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_minima_and_threshold(grid):\n",
    "    s1 = np.arange(len(grid.minima))\n",
    "#     plt.scatter(s1, grid.minima, s=0.1)\n",
    "#     print(grid.threshold)\n",
    "    s2, threshold = grid.threshold[:, 0], grid.threshold[:, 1]\n",
    "#     plt.xlim(-3000, 30000)\n",
    "#     plt.xlim(-3000, np.max(s2))\n",
    "#     plt.scatter(s2, threshold, s= 10)\n",
    "    plt.plot(s2, threshold)\n",
    "    return s2, threshold\n",
    "\n",
    "def plot_threshold(grid):\n",
    "    plt.plot(grid.threshold[:, 0], grid.threshold[:, 1])\n",
    "\n",
    "s2, threshold = plot_minima_and_threshold(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca67508",
   "metadata": {},
   "source": [
    "### Avalanche size frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d680e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_power_law(data):\n",
    "    '''Fits the power law using '''\n",
    "    # Define the power law function\n",
    "    \n",
    "    def power_law(x, m, b):\n",
    "        return m*x+ b\n",
    "    \n",
    "    filtered_ones_log = data\n",
    "    filtered_ones_log = data[data[:, 1] > 0]\n",
    "    \n",
    "    logx = filtered_ones_log[:,0]\n",
    "    logy = filtered_ones_log[:,1]\n",
    "\n",
    "    \n",
    "    initial_guess = [2, logy[0]]\n",
    "    bounds = [(-5,5), (logy[0]-0.5, logy[0]+0.5)]\n",
    "    \n",
    "    lower_bounds = [-np.inf,logy[0]-0.1]\n",
    "    upper_bounds = [np.inf,logy[0]+0.1]\n",
    "    \n",
    "    params, covariance = curve_fit(power_law, logx, logy, p0=initial_guess, bounds=(lower_bounds, upper_bounds))\n",
    "#     params, covariance = curve_fit(power_law, logx, logy)\n",
    "    # Fit the power law function to the data\n",
    "\n",
    "    # Get the fitted parameters\n",
    "    a_fit, b_fit = params\n",
    "    print(f\"m is {a_fit}\")\n",
    "    print(f\"b is {b_fit}\")\n",
    "\n",
    "    # Generate fitted curve\n",
    "    x_fit = np.linspace(logx[0], logx[-1], 10)\n",
    "    \n",
    "    y_fit = a_fit*x_fit+(b_fit)\n",
    "\n",
    "    return x_fit, y_fit , a_fit, b_fit\n",
    "\n",
    "\n",
    "frequencies = grid.avalanche_frequencies()\n",
    "\n",
    "log_frequencies = np.log(frequencies)\n",
    "x, y, m, b  = fit_power_law(log_frequencies)\n",
    "plt.scatter(log_frequencies[:,0], log_frequencies[:,1])\n",
    "plt.plot(x, y)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d32e976",
   "metadata": {},
   "source": [
    "## Running for different grid sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9bb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations_list = []\n",
    "\n",
    "for L in [50,100,200]:\n",
    "    grid = SimulationGrid(L)\n",
    "    grid.run_iterations(80000, save=False)\n",
    "    simulations_list.append(grid)\n",
    "    \n",
    "print(type(simulations_list[0]))\n",
    "# colors = ['r','g', 'b', 'o']\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "\n",
    "for indx, grid in enumerate(simulations_list):\n",
    "    print(indx)\n",
    "    print(grid.size)\n",
    "    name = f\"L={grid.size}\"\n",
    "    plt.plot(grid.threshold[:, 0], grid.threshold[:, 1], color= colors[indx], label=name)\n",
    "\n",
    "plt.title('Convergence')\n",
    "plt.legend()    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2ff2ae",
   "metadata": {},
   "source": [
    "### Plotting frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(simulations_list), sharey=True, sharex=True, figsize=(15, 5))\n",
    "\n",
    "for indx, (grid, ax) in enumerate(zip(simulations_list, axes)):\n",
    "    frequencies = grid.avalanche_frequencies()\n",
    "    log_frequencies = np.log(frequencies)\n",
    "    x, y , m ,b= fit_power_law(log_frequencies)\n",
    "    name = f\"m = {round(m,2)}, b = {round(b,2)}\"\n",
    "    ysum= np.sum(y)\n",
    "    colors = ['blue', 'green', 'red']\n",
    "    \n",
    "    ax.scatter(log_frequencies[:, 0], log_frequencies[:, 1], color=colors[indx], label=name)\n",
    "    ax.plot(x, y, color=colors[indx])\n",
    "\n",
    "    ax.set_xlabel('log(s)')\n",
    "    ax.set_ylabel('log(y)')\n",
    "    ax.set_title(f'L = {grid.size}')\n",
    "    ax.legend()\n",
    "    # Set x-axis limits\n",
    "#     ax.set_xlim(-0.2, 8)\n",
    "plt.suptitle('Frequency distribution of avalanche size')\n",
    "\n",
    "# Add legend to the last subplot\n",
    "axes[-1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f3b6b1",
   "metadata": {},
   "source": [
    "### Histogram distribution of fitness values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755921d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid1, grid2, grid3 = simulations_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1826e2",
   "metadata": {},
   "source": [
    "# Testing convergence under different lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19871640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
